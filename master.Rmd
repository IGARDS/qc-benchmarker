---
title: "Master Pipeline"
output:
  html_document: default
  pdf_document: default
date version: May 24, 2019
---

This file is meant to run all processing once the query has been uploaded. It is an .Rmd, but will not be used for display. The primary function is to perform file conversion and searching, with results kept in the workspace for ensuing .Rmd files to use when generating reports. Also we will write 5 .result files to be used to retrieve graphics displayed in middle iframe. These will have a value of 0, 1, 2, 3, or 4.  
processing in progress = 0  
good = 1  
marginal = 2  
bad = 3  
error = 4  
QUERY, OUTPUT_DIR are set at upload  
reference related files (.raw, .mzML, and .interact.pep.xml) should be present in /data/qc-benchmarker-data/

1. Load R packages

```{r Setup libs, echo=FALSE}
library(mzR)
library(MSnbase)
library(scales)
library(XML)
library(pepXMLTab)
library(ggplot2)

```



2. Call reference files, process QUERY, write .result files. In future iterations will perform lite search to determine if HeLa, yeast or E. coli

```{r Setup files, echo=FALSE}
DATA_DIR <- '/data/qc-benchmarker-data/'
REFERENCE <- paste(DATA_DIR,'2018-10-15_HeLa_OTOT',sep='')   # reference name for later use with different file types
AMOUNT_INJECTED <- 200                                       # ng HeLa injected (reference)
SPECTRAST_LIBRARY <- paste(DATA_DIR,'HeLa.splib',sep='')                   # HeLa library
FASTA_FILE <- paste(DATA_DIR,'up000005640.fasta',sep='')                   # sequence database
#MZML_DIR <- ''                                              # working directory is OUTPUT_DIR
#mzml_file <- paste(MZML_DIR,'/',QUERY,'.mzML',sep='')       # didn't use this abbreviation



# convert query to mzML
system(paste('wine msconvert', paste(OUTPUT_DIR,'/../',QUERY,'.raw',sep=''),'-v --mzML -o',OUTPUT_DIR))

query_file <- openMSfile(paste(QUERY, '.mzML', sep=''))
make <- instrumentInfo(query_file)$manufacturer
model <- instrumentInfo(query_file)$model
# cat('Query file is', make, model)

# write .result files as "processing in progress"
system('echo 0 > sample.result')
system('echo 0 > lc.result')
system('echo 0 > source.result')
system('echo 0 > ms1.result')
system('echo 0 > ms2.result')

```



3. Perform searches for ID-based metrics. Note that this step will not complete if something is wrong, and is a good check point to use and go straight to "can't process" which is 4 > .results. 0 in .results will be reserved for "in-progress".

```{r Searching, echo=FALSE}
# Perform SpectraST search
system(paste('/local/tpp/bin/spectrast -sL', SPECTRAST_LIBRARY, ' -sD', FASTA_FILE,
             ' -sTAA -sA! -s_HOM4 -sR! -sEpep.xml ', QUERY, '.mzML', sep = ''))
system(paste('/local/tpp/bin/xinteract -N', sub('$', '.interact.pep.xml', QUERY), 
             ' -p0.95 -l7 -PPM -O -D', FASTA_FILE, ' ', QUERY, '.pep.xml', sep = ''))
# if wine doesn't work use /local/tpp/bin/
			 
# Extract QC values from SpectraST search
# use already processed reference file
system(paste('/local/tpp/bin/idconvert ', DATA_DIR, REFERENCE, '.interact.pep.xml',sep='')) 
system(paste('/local/tpp/bin/idconvert ', QUERY, '.interact.pep.xml', sep='')) 

# not sure if the mzid is created in working_dir or in original xml location on DATA_DIR, and whether it is called interact.pep.mzid or just .mzid
reference_ids <- openIDfile(paste(OUTPUT_DIR,'/../', REFERENCE, '.mzid', sep=''))
query_ids <- openIDfile(paste(QUERY, '.mzid', sep=''))

PSMs <- c(nrow(psms(reference_ids)), nrow(psms(query_ids)))

# if query_ids is empty then write all 5 .result files with 4, but place this condition at the end of this file

```



4. Sample. Estimate loading and store. Generate structure with distribution of charge states. Calculate percent matched spectra to material.

```{r Sample, echo=FALSE}
reference_file <- openMSfile(paste(DATA_DIR, REFERENCE, '.mzML', sep=''))
# query_file <- openMSfile(paste(OUTPUT_DIR,'/../',QUERY, '.mzML', sep=''))      # we already read this in at the start

reference_TIC_load <- tic(reference_file)       # since we only use this to estimate load call it '_load'
query_TIC_load <- tic(query_file)

cat('Query TIC total area ', 100*sum(query_TIC_load)/sum(reference_TIC_load), '% of reference.',
    sep='')
cat('Est. amount injected ', AMOUNT_INJECTED*sum(query_TIC_load)/sum(reference_TIC_load), ' ng.',
    sep='')

# would like to use matched spectra as well in quality

# good (1)= 40% or greater of matched spectra
# marginal (2)= 20-40% of matched spectra
# bad (3) = <20% matched spectra

if((100*sum(query_TIC_load)/sum(reference_TIC_load)) < 50){
  system('echo 3 > sample.result')
} else if ((100*sum(query_TIC_load)/sum(reference_TIC_load)) < 80){
  system('echo 2 > sample.result')
} else {
  system('echo 1 > sample.result')
}

# render the sample html_document
rmarkdown::render("/data/qc-benchmarker/sample.Rmd", output_dir = OUTPUT_DIR)

```



5. LC; Estimate peak capacity. Calculate peak capacity as ID-free

```{r LC, echo=FALSE}
query <- readMSData(paste(QUERY, '.mzML', sep=''), msLevel = 1) # default is not onDisk, but this seems to avoid memory issue and is faster, but it makes the chromatogram() super slow
query_BPC <- chromatogram(query, aggregationFun = "max") 


# first calculate peak width with lag 1 and theoretical peak capacity
x <- as.numeric(query_BPC[1,1]@rtime)
y <- as.numeric(query_BPC[1,1]@intensity)

x2 <- seq(round(min(x)),round(max(x)),0.1)
y2 <- rep(0,length(x2))

for(i in 1:length(y2)) {
  j <- which.min(abs(x2[i]-x))
  y2[i] <- y[j]
}
  
fy2 <- Re(fft(fft(y2)*Conj(fft(y2)), inverse = TRUE))

max_fy2 <- max(fy2)
min_fy2_w <- min(fy2[1:1000])
for(i in 1:1000) {if(fy2[i]<(min_fy2_w+(max_fy2-min_fy2_w)/2)) break}
peak_width <- 1.412517*i*0.1 # FWHM = 1.412517 * (lag at autocorrelation half maximum for gaussian)
cat('Mean peak width (FWHM equivalent) =', signif(peak_width, digits=4), "seconds")

gradient_length <- 120*60 # in seconds; in future the gradient will be determined not hard coded
cat('Theor. peak capacity =', signif(gradient_length/peak_width, digits=4))


# Look at retention coeffecients
# Here we train a linear model (Palmblad *et al*., 2002) for predicting retention times, and compare the amino acid coefficients of the query model with those from the reference model. This will reveal changes in mobile phase composition, such as ionic strength or pH. The training is here done with R packages.
peptides <-c(); RTs <- c()
psms <- xmlToList(paste(tolower(QUERY), '.interact.pep.xml', sep=''))
for (i in seq(5,length(psms$msms_run_summary)-1)) {
    peptides <- c(peptides,as.character(psms$msms_run_summary[i]$spectrum_query$search_result$search_hit$.attrs['peptide']))
    RTs <- c(RTs,as.numeric(psms$msms_run_summary[i]$spectrum_query$.attrs['retention_time_sec']))
}
meanRT <- mean(RTs)
sdRT <- sd(RTs)
ZRTs <- (RTs - meanRT)/sdRT
 
nA<-c(); nR<-c(); nN<-c(); nD<-c(); nC<-c(); nE<-c(); nQ<-c(); nG<-c(); nH<-c(); nI<-c();
nL<-c(); nK<-c(); nM<-c(); nF<-c(); nP<-c(); nS<-c(); nT<-c(); nW<-c(); nY<-c(); nV<-c();

for (i in 1:length(peptides)) {
  nA[i] <- sum(charToRaw(peptides[i]) == charToRaw('A'))
  nR[i] <- sum(charToRaw(peptides[i]) == charToRaw('R'))
  nN[i] <- sum(charToRaw(peptides[i]) == charToRaw('N'))
  nD[i] <- sum(charToRaw(peptides[i]) == charToRaw('D'))
  nC[i] <- sum(charToRaw(peptides[i]) == charToRaw('C'))
  nE[i] <- sum(charToRaw(peptides[i]) == charToRaw('E'))
  nQ[i] <- sum(charToRaw(peptides[i]) == charToRaw('Q'))
  nG[i] <- sum(charToRaw(peptides[i]) == charToRaw('G'))
  nH[i] <- sum(charToRaw(peptides[i]) == charToRaw('H'))
  nI[i] <- sum(charToRaw(peptides[i]) == charToRaw('I'))
  nL[i] <- sum(charToRaw(peptides[i]) == charToRaw('L'))
  nK[i] <- sum(charToRaw(peptides[i]) == charToRaw('K'))
  nM[i] <- sum(charToRaw(peptides[i]) == charToRaw('M'))
  nF[i] <- sum(charToRaw(peptides[i]) == charToRaw('F'))
  nP[i] <- sum(charToRaw(peptides[i]) == charToRaw('P'))
  nS[i] <- sum(charToRaw(peptides[i]) == charToRaw('S'))
  nT[i] <- sum(charToRaw(peptides[i]) == charToRaw('T'))
  nW[i] <- sum(charToRaw(peptides[i]) == charToRaw('W'))
  nY[i] <- sum(charToRaw(peptides[i]) == charToRaw('Y'))
  nV[i] <- sum(charToRaw(peptides[i]) == charToRaw('V'))
}

fit <- lm(ZRTs ~ nA+nR+nN+nD+nC+nE+nQ+nG+nH+nI+nL+nK+nM+nF+nP+nS+nT+nW+nY+nV)
query_coeffs <- as.vector(coefficients(fit))

peptides <-c(); RTs <- c()
psms <- xmlToList(paste(DATA_DIR, REFERENCE, '.interact.pep.xml', sep=''))
for (i in seq(5,length(psms$msms_run_summary)-1)) {
    peptides <- c(peptides,as.character(psms$msms_run_summary[i]$spectrum_query$search_result$search_hit$.attrs['peptide']))
    RTs <- c(RTs,as.numeric(psms$msms_run_summary[i]$spectrum_query$.attrs['retention_time_sec']))
}
meanRT <- mean(RTs)
sdRT <- sd(RTs)
ZRTs <- (RTs - meanRT)/sdRT

nA<-c(); nR<-c(); nN<-c(); nD<-c(); nC<-c(); nE<-c(); nQ<-c(); nG<-c(); nH<-c(); nI<-c();
nL<-c(); nK<-c(); nM<-c(); nF<-c(); nP<-c(); nS<-c(); nT<-c(); nW<-c(); nY<-c(); nV<-c();

for (i in 1:length(peptides)) {
  nA[i] <- sum(charToRaw(peptides[i]) == charToRaw('A'))
  nR[i] <- sum(charToRaw(peptides[i]) == charToRaw('R'))
  nN[i] <- sum(charToRaw(peptides[i]) == charToRaw('N'))
  nD[i] <- sum(charToRaw(peptides[i]) == charToRaw('D'))
  nC[i] <- sum(charToRaw(peptides[i]) == charToRaw('C'))
  nE[i] <- sum(charToRaw(peptides[i]) == charToRaw('E'))
  nQ[i] <- sum(charToRaw(peptides[i]) == charToRaw('Q'))
  nG[i] <- sum(charToRaw(peptides[i]) == charToRaw('G'))
  nH[i] <- sum(charToRaw(peptides[i]) == charToRaw('H'))
  nI[i] <- sum(charToRaw(peptides[i]) == charToRaw('I'))
  nL[i] <- sum(charToRaw(peptides[i]) == charToRaw('L'))
  nK[i] <- sum(charToRaw(peptides[i]) == charToRaw('K'))
  nM[i] <- sum(charToRaw(peptides[i]) == charToRaw('M'))
  nF[i] <- sum(charToRaw(peptides[i]) == charToRaw('F'))
  nP[i] <- sum(charToRaw(peptides[i]) == charToRaw('P'))
  nS[i] <- sum(charToRaw(peptides[i]) == charToRaw('S'))
  nT[i] <- sum(charToRaw(peptides[i]) == charToRaw('T'))
  nW[i] <- sum(charToRaw(peptides[i]) == charToRaw('W'))
  nY[i] <- sum(charToRaw(peptides[i]) == charToRaw('Y'))
  nV[i] <- sum(charToRaw(peptides[i]) == charToRaw('V'))
}

fit <- lm(ZRTs ~ nA+nR+nN+nD+nC+nE+nQ+nG+nH+nI+nL+nK+nM+nF+nP+nS+nT+nW+nY+nV)
reference_coeffs <- as.vector(coefficients(fit))

aa_olc <- c('O','A','R','N','D','C','E','Q','G','H','I','L','K','M','F','P','S','T','W','Y','V')

aa_colors<-c('black','orange', 'blue', 'magenta', 'red', 'green', 'red', 'magenta', 'orange',
           'blue', 'green', 'green', 'blue', 'green', 'green', 'green', 'orange', 
           'orange', 'green', 'green', 'green', 'yellow', 'yellow', 'yellow', 'yellow')
limits <- c(min(reference_coeffs[1:21], query_coeffs[1:21]), max(reference_coeffs[1:21], query_coeffs[1:21]))
plot(reference_coeffs[1:21], query_coeffs[1:21], pch=19, cex=2.5, 
     col=alpha(aa_colors, 0.6), xlab='reference retention coefficient (Z-score)', 
     ylab='query retention coefficient (Z-score)', xlim=limits, ylim=limits, text(reference_coeffs[1:21], query_coeffs[1:21]+0.0047*(max(query_coeffs[1:21])-min(query_coeffs[1:21])), aa_olc, col='black', font=2, cex=0.8)) 

abline(a=0, b=1, lty=2)

coeffs_model <- lm(query_coeffs~reference_coeffs)
slp <-  coef(coeffs_model)[2]


# need to write lowest quality so make score and take worst (1 good, 2 marginal, 3 bad)

# quality score based on peak capacity
signif(gradient_length/peak_width)
if((gradient_length/peak_width) < 200){
  peak_capacity_qual <- 3
} else if ((gradient_length/peak_width) < 300){
  peak_capacity_qual <- 2
} else {
  peak_capacity_qual <- 1
}

# quality score based on slope (slp)
if(abs(slp-1) > 0.2){
  coeff_qual <- 3
} else if (abs(slp-1) > 0.1){
  coeff_qual <- 2
} else {
  coeff_qual <- 1
}

# take highest score (higher is more bad) and write to lc.result
if(peak_capacity_qual > coeff_qual){
  system(paste('echo ', peak_capacity_qual,' > lc.result', sep = ''))
} else {
  system(paste('echo ', coeff_qual,' > lc.result', sep = ''))
}

# render the LC html_document
rmarkdown::render("/data/qc-benchmarker/lc.Rmd", output_dir = OUTPUT_DIR)

```


6. Source. Compare signal stability

```{r Source, echo=FALSE}
# query <- readMSData(paste(OUTPUT_DIR,'/../',QUERY, '.mzML', sep=''), msLevel = 1) # already did this for LC section
query_TIC <- chromatogram(query, aggregationFun = "sum")

reference <- readMSData(paste(DATA_DIR, REFERENCE, '.mzML', sep=''), msLevel = 1)
reference_TIC <- chromatogram(reference, aggregationFun = "sum")


# determine signal stability with lag-1 autocorrelation
x <- as.numeric(query_TIC[1,1]@intensity)
query_cor <- cor(x[-length(x)],x[-1])
x <- as.numeric(reference_TIC[1,1]@intensity)
reference_cor <- cor(x[-length(x)],x[-1])

# TIC intensity
median_TIC <- median(as.numeric(query_TIC[1,1]@intensity))

if((query_cor) < 0.5){
  system('echo 3 > source.result')
} else if ((query_cor) < 0.8){
  system('echo 2 > source.result')
} else {
  system('echo 1 > source.result')
}

# render the source html_document
rmarkdown::render("/data/qc-benchmarker/source.Rmd", output_dir = OUTPUT_DIR)

```


7. MS1. TIC and mass error can be used for quality judgement

```{r MS1, echo=FALSE}
# Extract QC values from query and compare with reference

# the following was performed for sample section
#reference_file <- openMSfile(paste(DATA_DIR, REFERENCE, '.mzML', sep=''))
#query_file <- openMSfile(paste(QUERY, '.mzML', sep=''))
#
#reference_TIC <- tic(reference_file)
#query_TIC <- tic(query_file)

cat('Query TIC total area ', 100*sum(query_TIC_load)/sum(reference_TIC_load), '% of reference.',
    sep='')
# cat('Est. amount injected ', AMOUNT_INJECTED*sum(query_TIC_load)/sum(reference_TIC_load), ' ng.',
#    sep='')


# determine mass error using experimental m/z versus calculated m/z of identified PSMs. Since the library was constructed using isotope correction, there are calculated masses that are using monoisotopic, though this was not selected, therefore only m/z differences less than 0.1 were used for these calculations.

A <- psms(query_ids)
mz_error <- A[,5]-A[,6]
mz <- A[,6]
z <- A[,2]
mean_mz_error <- mean(mz_error[abs(mz_error)<0.1]/mz[abs(mz_error)<0.1])

hist(1e6*mz_error[abs(mz_error)<0.10]/mz[abs(mz_error)<0.10], breaks = 2000, main = 'ppm error', xlab = 'ppm', xlim = c(-20,20) )

plot(mz, 1e6*mz_error/mz, col=alpha('blue', 1), pch='.', ylim = c(-10,10), xlab='AvePrecursorMz', ylab='MassDiff (in ppm)')

cat('Average MS1 mass error: ', signif(1e6*mean_mz_error, digits=2), ' ppm.', sep='')

# make quality call using mass error. Should be based on instrument type
if((abs(1e6*mean_mz_error)) > 15){
  system('echo 3 > ms1.result')
} else if ((abs(1e6*mean_mz_error)) > 10){
  system('echo 2 > ms1.result')
} else {
  system('echo 1 > ms1.result')
}

# render the ms1 html_document
rmarkdown::render("/data/qc-benchmarker/ms1.Rmd", output_dir = OUTPUT_DIR)

```



8. MS2. PSMs and mass error will be used for quality

```{r MS2, echo=FALSE}
PSMs <- c(nrow(psms(reference_ids)), nrow(psms(query_ids)))

if((100*nrow(psms(reference_ids))/nrow(psms(query_ids))) < 50){
  system('echo 3 > ms2.result')
} else if ((100*nrow(psms(reference_ids))/nrow(psms(query_ids))) < 80){
  system('echo 2 > ms2.result')
} else {
  system('echo 1 > ms2.result')
}

# render the ms2 html_document
rmarkdown::render("/data/qc-benchmarker/ms2.Rmd", output_dir = OUTPUT_DIR)

```



9. Call errors. If query_ids is empty then write all 5 .result files with 4.

```{r Error Call, echo=FALSE}
if(nrow(psms(query_ids)) < 1){
  system('echo 4 > sample.result')
  system('echo 4 > LC.result')
  system('echo 4 > source.result')
  system('echo 4 > ms1.result')
  system('echo 4 > ms2.result')
}

```